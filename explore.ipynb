{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] test ramvid\n",
    "- [ ] test docker\n",
    "- [ ] test docker in ramvid\n",
    "- [ ] test kubernetes\n",
    "- [ ] test ramvid in docker in kubernetes\n",
    "- [ ] lightning template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">bound</span><span style=\"color: #000000; text-decoration-color: #000000\"> method Typer.command of &lt;typer.main.Typer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x11b293af0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&gt;</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; font-style: italic\">def </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Typer.command</span><span style=\"font-weight: bold\">(</span>name: Optional<span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, *, cls: Optional<span style=\"font-weight: bold\">[</span>Type<span style=\"font-weight: bold\">[</span>typer.core.TyperCommand<span style=\"font-weight: bold\">]]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> context_settings: Optional<span style=\"font-weight: bold\">[</span>Dict<span style=\"font-weight: bold\">[</span>Any, Any<span style=\"font-weight: bold\">]]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, help: Optional<span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, epilog: Optional<span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> short_help: Optional<span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span> = <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, options_metavar: str = <span style=\"color: #008000; text-decoration-color: #008000\">'[OPTIONS]'</span>, add_help_option: bool = <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,             <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> no_args_is_help: bool = <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, hidden: bool = <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, deprecated: bool = <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, rich_help_panel: Optional<span style=\"font-weight: bold\">[</span>str<span style=\"font-weight: bold\">]</span> = <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">typer.models.DefaultPlaceholder</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x11b463610</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\"> -</span><span style=\"font-weight: bold\">&gt;</span> Callable<span style=\"font-weight: bold\">[[</span>~CommandFunctionType<span style=\"font-weight: bold\">]</span>,                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> ~CommandFunctionType<span style=\"font-weight: bold\">]</span>:                                                                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span><span style=\"font-style: italic\"> attribute(s) not shown.</span> Run <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">inspect</span><span style=\"font-weight: bold\">(</span>inspect<span style=\"font-weight: bold\">)</span> for options.                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mbound\u001b[0m\u001b[39m method Typer.command of <typer.main.Typer object at \u001b[0m\u001b[1;36m0x11b293af0\u001b[0m\u001b[39m>\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[3;96mdef \u001b[0m\u001b[1;31mTyper.command\u001b[0m\u001b[1m(\u001b[0mname: Optional\u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m, *, cls: Optional\u001b[1m[\u001b[0mType\u001b[1m[\u001b[0mtyper.core.TyperCommand\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m,           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m context_settings: Optional\u001b[1m[\u001b[0mDict\u001b[1m[\u001b[0mAny, Any\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m, help: Optional\u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m, epilog: Optional\u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m,    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m short_help: Optional\u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m = \u001b[3;35mNone\u001b[0m, options_metavar: str = \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32mOPTIONS\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m, add_help_option: bool = \u001b[3;92mTrue\u001b[0m,             \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m no_args_is_help: bool = \u001b[3;91mFalse\u001b[0m, hidden: bool = \u001b[3;91mFalse\u001b[0m, deprecated: bool = \u001b[3;91mFalse\u001b[0m, rich_help_panel: Optional\u001b[1m[\u001b[0mstr\u001b[1m]\u001b[0m = \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1m<\u001b[0m\u001b[1;95mtyper.models.DefaultPlaceholder\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x11b463610\u001b[0m\u001b[39m>\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m -\u001b[0m\u001b[1m>\u001b[0m Callable\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m~CommandFunctionType\u001b[1m]\u001b[0m,                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m ~CommandFunctionType\u001b[1m]\u001b[0m:                                                                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[1;36m27\u001b[0m\u001b[3m attribute(s) not shown.\u001b[0m Run \u001b[1;35minspect\u001b[0m\u001b[1m(\u001b[0minspect\u001b[1m)\u001b[0m for options.                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyfig.utils import rinspect\n",
    "from typer import Typer\n",
    "app = Typer()\n",
    "# rinspect(app)\n",
    "rinspect(app.command)\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Pyfig(BaseModel):\n",
    "    \"\"\"Configuration for the training script.\"\"\"\n",
    "\n",
    "    data_path: str = \"./data/\"\n",
    "    batch_size: int = 64\n",
    "    learning_rate: float = 1e-3\n",
    "    num_epochs: int = 10\n",
    "    num_workers: int = 4\n",
    "    model_save_path: str = \"./models/\"\n",
    "    wandb_project_name: str = \"project-name\"\n",
    "    wandb_api_key: str = os.environ.get(\"WANDB_API_KEY\")\n",
    "    seed: int = 42\n",
    "    accelerator: Optional[Any] = None\n",
    "    checkpoint_frequency: int = 1\n",
    "\n",
    "    log_model: bool = False\n",
    "\n",
    "\n",
    "c = Pyfig(\n",
    "\n",
    ")\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset class.\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str):\n",
    "        self.data_path = data_path\n",
    "        # Load your data from data_path\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Return the length of the dataset\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        # Return a single data sample\n",
    "        pass\n",
    "\n",
    "class CustomModel(pl.LightningModule):\n",
    "    \"\"\"Custom model class.\"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate: float):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = nn.Sequential(\n",
    "            # Add your model layers here\n",
    "        )\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.val_acc = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        self.train_acc(y_hat.softmax(dim=-1), y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: tuple, batch_idx: int) -> torch.Tensor:\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_function(y_hat, y)\n",
    "        self.val_acc(y_hat.softmax(dim=-1), y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.val_acc, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self) -> optim.Optimizer:\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "\n",
    "c = Config()\n",
    "\n",
    "def main(cfg: Config):\n",
    "    \"\"\"Main training function.\"\"\"\n",
    "\n",
    "    pl.seed_everything(cfg.seed)\n",
    "\n",
    "    accelerator = Accelerator(\n",
    "        device_placement=True,  # Automatically places tensors on the proper device\n",
    "        fp16=True,  # Enables automatic mixed precision training (AMP)\n",
    "        cpu=True,  # Forces the use of CPU even when GPUs are available\n",
    "        split_batches=True,  # Splits the batches on the CPU before sending them to the device\n",
    "        num_processes=1,  # Number of processes to use for distributed training (1 means no distributed training)\n",
    "        local_rank=0,  # Local rank of the process (for distributed training)\n",
    "    )\n",
    "    cfg.accelerator = accelerator\n",
    "\n",
    "    dataset = CustomDataset(cfg.data_path)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_workers=cfg.num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=cfg.batch_size,\n",
    "        num_workers=cfg.num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    model = CustomModel(cfg.learning_rate)\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=cfg.wandb_project_name,\n",
    "        log_model=c.log_model,\n",
    "    )\n",
    "\n",
    "    wandb_logger.watch(model)\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=cfg.model_save_path,\n",
    "        filename=\"model-{epoch:02d}-{val_loss:.2f}\",\n",
    "        save_top_k=1,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_weights_only=True,\n",
    "        save_last=True,\n",
    "        period=cfg.checkpoint_frequency,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg.num_epochs,\n",
    "        accelerator=cfg.accelerator,\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        gpus=torch.cuda.device_count(),\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
